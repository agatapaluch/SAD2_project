\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{hyperref}

\usepackage{graphicx}

\title{Report from project SAD2}
\author{}
\date{}

\begin{document}
\maketitle

\section{Datasets and Ground Truth}
Datasets (simulated trajectories) and their corresponding ground-truth Boolean networks are generated by sweeping the following parameter grid:

\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Values} \\
\midrule
\multicolumn{2}{l}{\textit{Network parameters}} \\
\midrule
\texttt{n\_nodes} & \{5, 8, 11, 16\} \\
\texttt{network\_seed} & \{0, 1\} \\
\midrule
\multicolumn{2}{l}{\textit{Trajectory parameters}} \\
\midrule
\texttt{n\_trajectories} & \{1, 5, 20\} \\
\texttt{sync transition} & \{True, False\} \\
\texttt{trajectory\_len} & \{5, 20, 100\} \\
\texttt{sampling\_frequency} & \{1, 3\} \\
\bottomrule
\end{tabular}
\caption{Parameter grid used for generating datasets and ground-truth networks.}
\end{table}

Larger networks (e.g., \texttt{n\_nodes} $>$ 12) significantly increased runtime for both dataset generation and BNFinder inference, so instead of exhaustively testing all sizes we used a representative set spanning the range $[5,16]$. In total, the sweep contains $4 \times 2  \times 2 \times 3 \times 3 \times 2  = 288$ parameter combinations, which already requires substantial computational effort during evaluation. In addition, we tracked the \texttt{attractor\_state\_percentage}, which varies between $0$ and $1$ depending on the trajectory. Overall, the chosen grid allowed us to assess which conditions favor accurate graph-structure inference.


\section{Evaluation}
\begin{itemize}[leftmargin=*]
  \item \textbf{Reconstruction setup.} We used the simplest BNFinder invocation:
  \texttt{bnf -e input1.txt -n output1.sif -l 3}. The key adjustment was \texttt{-l 3}, which limits each Boolean function to at most three parents; this greatly reduces the search space and speeds up reconstruction.

  \item \textbf{Scoring functions.} We evaluated candidate network structures using two BNFinder-recommended scores: \emph{Minimal Description Length (MDL)} and \emph{BDe (Bayesian--Dirichlet equivalence)}.

\item \textbf{Loss functions (accuracy metrics).} We measured structural prediction error using \texttt{edge jaccard distance} and \texttt{graph edit distance}: together they capture both \emph{local edge overlap} (exact wiring agreement) and \emph{global topological discrepancy} (how many edits are needed to transform one graph into the other). We chose these metrics because they are widely used in graph-structure evaluation and provide complementary views of reconstruction quality.

\item \textbf{Final conclusions}
We ran a wide range of parameter configurations, and presenting all plots here would be unreadable - we chosen the most significant ones. The results varied substantiallyâ€”from near-perfect reconstruction to almost no correct edges. Overall, the most influential factor was dataset size: more trajectories and longer trajectories consistently improved performance (Figure~3). This matches intuition, since larger datasets provide more information for inference. In contrast, we did not observe a clear difference between synchronous and asynchronous transitions, nor between the MDL and BDe scoring methods. Finally, we observed a slight negative (figure 4) correlation between network size and reconstruction accuracy, which is also intuitive: larger networks are generally harder to infer accurately.

\begin{figure}[h]
  \centering
  \begin{minipage}{0.49\textwidth}
    \centering
    \includegraphics[width=\linewidth]{bar_jaccard_trajlen_MDL.png}
    \caption*{\small Jaccard vs.\ trajectory length (MDL)}
  \end{minipage}\hfill
  \begin{minipage}{0.49\textwidth}
    \centering
    \includegraphics[width=\linewidth]{bar_jaccard_ntraj_MDL.png}
    \caption*{\small Jaccard vs.\ number of trajectories (MDL)}
  \end{minipage}
  \caption{Edge Jaccard distance under MDL for two dataset axes.}
  \label{fig:jaccard_mdl_side_by_side}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.75\linewidth]{bar_jaccard_nodes_MDL.png}
  \caption{Edge Jaccard distance under MDL as a function of network size (\texttt{n\_nodes}).}
  \label{fig:jaccard_mdl_nodes}
\end{figure}


\end{itemize}

\section{Challenges encountered}
\begin{itemize}[leftmargin=*]
  \item \textbf{Legacy environment constraints.} One of the biggest challenges was setting up a fully compatible Python~2.7 environment (libraries, type checking, and tooling), since BNFinder does not support Python~3+. This turned out to be a valuable lesson in reproducibility: some of us managed the setup via \texttt{pyenv}, while others had to rely on Docker due to limited compatibility of their local machines with that early of a Python version.

  \item \textbf{Computational cost of the sweep.} To meaningfully assess how inference quality depends on key parameters (e.g., transition mode, network size etc.), we needed to run evaluations for a few hours, which limited how many additional combinations we could explore. To reduce runtime, we parallelized runs where possible and used BNFinder's \texttt{-l} option to cap the maximum number of parents per node, substantially decreasing computational burden.
\end{itemize}


\end{document}
